{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Writing and Validating Data in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ReadWriteVal</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15b18777940>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сначала создадим наш экземпляр PySpark!\n",
    "\n",
    "# Пользователи ПК могут использовать следующие две строки кода, но пользователям Mac это не нужно\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Может занять некоторое время на месте\n",
    "spark = SparkSession.builder.appName(\"ReadWriteVal\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "DataFrame эквивалентен реляционной таблице в Spark SQL и может быть создан с использованием различных функций в SparkSession.\n",
    "\n",
    "Сначала давайте попробуем прочитать файл csv, содержащий список учеников и их оценки.\n",
    "\n",
    "**Source:** https://www.kaggle.com/spscientist/students-performance-in-exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начнем с чтения базового набора данных csv\n",
    "# Сообщите Spark о заголовке и определите типы схемы!\n",
    "\n",
    "path =\"Datasets/\"\n",
    "\n",
    "# Некоторые данные csv\n",
    "students = spark.read.csv(path+'students.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parquet Files**\n",
    "\n",
    "Теперь попробуйте прочитать паркетный файл. Это наиболее распространенный тип данных в мире больших данных. Почему? потому что это самый компактный способ хранения файлов (даже лучше, чем заархивированные файлы!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|  registration_dttm| id|first_name|last_name|           email|gender|    ip_address|              cc|  country|birthdate|   salary|           title|comments|\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|2016-02-03 10:55:29|  1|    Amanda|   Jordan|ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|Internal Auditor|   1E+02|\n",
      "|2016-02-03 20:04:03|  2|    Albert|  Freeman| afreeman1@is.gd|  Male|218.111.175.34|                |   Canada|1/16/1968|150280.17|   Accountant IV|        |\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet = spark.read.parquet(path+'users1.parquet')\n",
    "parquet.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделенные паркетные файлы**\n",
    "\n",
    "Фактически, большинство больших наборов данных будут разделены. Вот как можете собрать все части (части) набора данных одной простой командой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|  registration_dttm| id|first_name|last_name|           email|gender|    ip_address|              cc|  country|birthdate|   salary|           title|comments|\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|2016-02-03 10:55:29|  1|    Amanda|   Jordan|ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|Internal Auditor|   1E+02|\n",
      "|2016-02-03 20:04:03|  2|    Albert|  Freeman| afreeman1@is.gd|  Male|218.111.175.34|                |   Canada|1/16/1968|150280.17|   Accountant IV|        |\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partitioned = spark.read.parquet(path+'users*')\n",
    "partitioned.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы также можете выбрать чтение только определенного набора паркетных файлов. Скажем, например, что вам нужны только пользователи1 и пользователи2, а не пользователи3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+--------------------+------+---------------+-------------------+--------------------+----------+---------+--------------------+--------------------+\n",
      "|  registration_dttm| id|first_name|last_name|               email|gender|     ip_address|                 cc|             country| birthdate|   salary|               title|            comments|\n",
      "+-------------------+---+----------+---------+--------------------+------+---------------+-------------------+--------------------+----------+---------+--------------------+--------------------+\n",
      "|2016-02-03 10:55:29|  1|    Amanda|   Jordan|    ajordan0@com.com|Female|    1.197.201.2|   6759521864920116|           Indonesia|  3/8/1971| 49756.53|    Internal Auditor|               1E+02|\n",
      "|2016-02-03 20:04:03|  2|    Albert|  Freeman|     afreeman1@is.gd|  Male| 218.111.175.34|                   |              Canada| 1/16/1968|150280.17|       Accountant IV|                    |\n",
      "|2016-02-03 04:09:31|  3|    Evelyn|   Morgan|emorgan2@altervis...|Female|   7.161.136.94|   6767119071901597|              Russia|  2/1/1960|144972.51| Structural Engineer|                    |\n",
      "|2016-02-03 03:36:21|  4|    Denise|    Riley|    driley3@gmpg.org|Female|  140.35.109.83|   3576031598965625|               China|  4/8/1997| 90263.05|Senior Cost Accou...|                    |\n",
      "|2016-02-03 08:05:31|  5|    Carlos|    Burns|cburns4@miitbeian...|      | 169.113.235.40|   5602256255204850|        South Africa|          |     null|                    |                    |\n",
      "|2016-02-03 10:22:34|  6|   Kathryn|    White|  kwhite5@google.com|Female| 195.131.81.179|   3583136326049310|           Indonesia| 2/25/1983| 69227.11|   Account Executive|                    |\n",
      "|2016-02-03 11:33:08|  7|    Samuel|   Holmes|sholmes6@foxnews.com|  Male| 232.234.81.197|   3582641366974690|            Portugal|12/18/1987| 14247.62|Senior Financial ...|                    |\n",
      "|2016-02-03 09:47:06|  8|     Harry|   Howell| hhowell7@eepurl.com|  Male|   91.235.51.73|                   |Bosnia and Herzeg...|  3/1/1962|186469.43|    Web Developer IV|                    |\n",
      "|2016-02-03 06:52:53|  9|      Jose|   Foster|   jfoster8@yelp.com|  Male|   132.31.53.61|                   |         South Korea| 3/27/1992|231067.84|Software Test Eng...|               1E+02|\n",
      "|2016-02-03 21:29:47| 10|     Emily|  Stewart|estewart9@opensou...|Female| 143.28.251.245|   3574254110301671|             Nigeria| 1/28/1997| 27234.28|     Health Coach IV|                    |\n",
      "|2016-02-03 03:10:42| 11|     Susan|  Perkins| sperkinsa@patch.com|Female|    180.85.0.62|   3573823609854134|              Russia|          |210001.95|                    |                    |\n",
      "|2016-02-03 21:04:34| 12|     Alice|    Berry|aberryb@wikipedia...|Female| 246.225.12.189|   4917830851454417|               China| 8/12/1968| 22944.53|    Quality Engineer|                    |\n",
      "|2016-02-03 21:48:17| 13|    Justin|    Berry|jberryc@usatoday.com|  Male|   157.7.146.43|6331109912871813274|              Zambia| 8/15/1975| 44165.46|Structural Analys...|                    |\n",
      "|2016-02-04 00:46:52| 14|     Kathy| Reynolds|kreynoldsd@redcro...|Female|  81.254.172.13|   5537178462965976|Bosnia and Herzeg...| 6/27/1970|286592.99|           Librarian|                    |\n",
      "|2016-02-03 11:53:23| 15|   Dorothy|   Hudson|dhudsone@blogger.com|Female|       8.59.7.0|   3542586858224170|               Japan|12/20/1989|157099.71|  Nurse Practicioner|<script>alert('hi...|\n",
      "|2016-02-03 03:44:01| 16|     Bruce|   Willis|bwillisf@bluehost...|  Male|239.182.219.189|   3573030625927601|              Brazil|          |239100.65|                    |                    |\n",
      "|2016-02-03 03:57:45| 17|     Emily|  Andrews|eandrewsg@cornell...|Female| 29.231.180.172|     30271790537626|              Russia| 4/13/1990|116800.65|        Food Chemist|                    |\n",
      "|2016-02-03 19:44:24| 18|   Stephen|  Wallace|swallaceh@netvibe...|  Male|  152.49.213.62|   5433943468526428|             Ukraine| 1/15/1978|248877.99|Account Represent...|                    |\n",
      "|2016-02-03 14:45:54| 19|  Clarence|   Lawson|clawsoni@vkontakt...|  Male| 107.175.15.152|   3544052814080964|              Russia|          |177122.99|                    |                    |\n",
      "|2016-02-03 13:30:36| 20|   Rebecca|     Bell| rbellj@bandcamp.com|Female|172.215.104.127|                   |               China|          |137251.19|                    |                    |\n",
      "+-------------------+---+----------+---------+--------------------+------+---------------+-------------------+--------------------+----------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обратите внимание, что параметр .option (\"basePath\", path) используется для отмены автоматической функции\n",
    "# что исключит секционированную переменную в результирующем фрейме данных.\n",
    "# Я предпочитаю иметь информацию о разделах в моем новом фрейме данных лично.\n",
    "users1_2 = spark.read.option(\"basePath\", path).parquet(path+'users1.parquet', path+'users2.parquet')\n",
    "users1_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка данных\n",
    "\n",
    "Затем нужно будет убедиться, что фрейм данных был прочитан правильно. Позже перейдем к более детальной оценке данных, но сначала нам нужно убедиться, что все типы переменных были введены правильно и что значения действительно были введены ... иногда это не так :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|   lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|standard|                   none|        90|           95|           93|\n",
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Получите первоначальное представление о вашем фрейме данных\n",
    "students.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если ваш фрейм данных - это больше, чем просто несколько переменных, этот метод намного лучше\n",
    "students.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Обратите внимание на типы здесь:\n",
    "print(type(students))\n",
    "studentsPdf = students.toPandas()\n",
    "print(type(studentsPdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n",
      "None\n",
      "\n",
      "['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n",
      "\n",
      "DataFrame[summary: string, gender: string, race/ethnicity: string, parental level of education: string, lunch: string, test preparation course: string, math score: string, reading score: string, writing score: string]\n"
     ]
    }
   ],
   "source": [
    "# Резюме ваших данных:\n",
    "\n",
    "#show the data (like df.head())\n",
    "print(students.printSchema())\n",
    "print(\"\")\n",
    "print(students.columns)\n",
    "print(\"\")\n",
    "print(students.describe()) # Not so fond of this one but to each their own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntegerType"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если нужно получить тип только ОДНОГО столбца по имени, вы можете использовать эту функцию:\n",
    "students.schema['math score'].dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        math score|\n",
      "+-------+------------------+\n",
      "|  count|              1000|\n",
      "|   mean|            66.089|\n",
      "| stddev|15.163080096009454|\n",
      "|    min|                 0|\n",
      "|    max|               100|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Аккуратная функция \"описания\"\n",
    "students.describe(['math score']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------------+\n",
      "|summary|math score|reading score|writing score|\n",
      "+-------+----------+-------------+-------------+\n",
      "|  count|      1000|         1000|         1000|\n",
      "|    min|         0|           17|           10|\n",
      "|    25%|        57|           59|           57|\n",
      "|    75%|        77|           79|           79|\n",
      "|    max|       100|          100|          100|\n",
      "+-------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Сводная функция\n",
    "students.select(\"math score\", \"reading score\",\"writing score\").summary(\"count\", \"min\", \"25%\", \"75%\", \"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как указать типы данных при чтении в наборах данных.\n",
    "\n",
    "Некоторые типы данных упрощают вывод схемы (например, табличные форматы, такие как csv, которые покажем позже).\n",
    "\n",
    "Однако вам часто приходится устанавливать схему самостоятельно, если вы не имеете дело с методом .read, который не имеет встроенного inferSchema ().\n",
    "\n",
    "В Spark есть все необходимые для этого инструменты, просто для этого требуется очень специфическая структура:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,DateType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нам нужно создать список полей структуры \n",
    "    * : имя параметра: строка, имя поля. \n",
    "    * : param dataType:: class: DataType поля. \n",
    "    * : param nullable: boolean, может ли поле быть нулевым (None) или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField(\"name\", StringType(), True),\n",
    "               StructField(\"email\", StringType(), True),\n",
    "               StructField(\"city\", StringType(), True),\n",
    "               StructField(\"mac\", StringType(), True),\n",
    "               StructField(\"timestamp\", DateType(), True),\n",
    "               StructField(\"creditcard\", StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз мы сделаем файл .json :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = spark.read.json(path+'people.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- mac: string (nullable = true)\n",
      " |-- timestamp: date (nullable = true)\n",
      " |-- creditcard: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>mac</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>creditcard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keeley Bosco</td>\n",
       "      <td>katlyn@jenkinsmaggio.net</td>\n",
       "      <td>Lake Gladysberg</td>\n",
       "      <td>08:fd:0b:cd:77:f7</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1228-1221-1221-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rubye Jerde</td>\n",
       "      <td>juvenal@johnston.name</td>\n",
       "      <td>None</td>\n",
       "      <td>90:4d:fa:42:63:a2</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1228-1221-1221-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss Darian Breitenberg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>f9:0e:d3:40:cb:e9</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                     email             city  \\\n",
       "0                     None                      None             None   \n",
       "1             Keeley Bosco  katlyn@jenkinsmaggio.net  Lake Gladysberg   \n",
       "2              Rubye Jerde     juvenal@johnston.name             None   \n",
       "3  Miss Darian Breitenberg                      None             None   \n",
       "\n",
       "                 mac   timestamp           creditcard  \n",
       "0               None        None                 None  \n",
       "1  08:fd:0b:cd:77:f7  2015-04-25  1228-1221-1221-1431  \n",
       "2  90:4d:fa:42:63:a2  2015-04-25  1228-1221-1221-1431  \n",
       "3  f9:0e:d3:40:cb:e9  2015-04-25                 None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запись данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|     fruit|quantity|\n",
      "+----------+--------+\n",
      "|      Pear|      10|\n",
      "|    Orange|      36|\n",
      "|    Banana|     123|\n",
      "|      Kiwi|      48|\n",
      "|     Peach|      16|\n",
      "|Strawberry|       1|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values = [('Pear',10),('Orange',36),('Banana',123),('Kiwi',48),('Peach',16),('Strawberry',1)]\n",
    "df = spark.createDataFrame(values,['fruit','quantity'])\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
